---
title: "Math308 Midterm Project"
author: "Christina Wei", "Paul Mandelos"
date: "2024-03-05"
output: pdf_document
---

```{r}
library(readr)
library (irlba)
library (ggplot2)
```


```{r}
co_occur_M <- read.csv('/Users/paulmandelos/Downloads/co_occur.csv')
dictionary <- readLines('/Users/paulmandelos/Downloads/dictionary.txt')
M_normalized <- log1p(as.matrix(co_occur_M))
```                                                                                                                            


## Function to find co-occurrence
```{r}
# Function to find co-occurrence count of two words
find_cooccurrence <- function(word1, word2, dictionary, co_occurrence_M) {
  # Find indices of the words in the dictionary
  index1 <- which(dictionary == word1)
  index2 <- which(dictionary == word2)
  
  # Check if both words are in the dictionary
  if(length(index1) == 0 | length(index2) == 0) {
    return(NA) # Return NA if either word is not found
  }
  
  # Return co-occurrence count
  co_occurrence_M[index1, index2]
}


```


## Testing the Function
```{r}
# Example: Find co-occurrence of "king" and "queen"
cooccurrence_king_queen <- find_cooccurrence("king", "queen", dictionary, M_normalized)
print(paste("Co-occurrence of 'king' and 'queen':", cooccurrence_king_queen))

# Example: Find co-occurrence of "power" and "energy"
cooccurrence_power_energy <- find_cooccurrence("power", "energy", dictionary, M_normalized)
print(paste("Co-occurrence of 'power' and 'energy':", cooccurrence_power_energy))

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.



#2. 
Based on the plot, it indicates that M is low rank matrix since the singular values shows a rapid decay, where the initial values are significantly larger than that follow, and they quickly diminish in magnitude. It means that the data or pattern in M can be captured with fewer dimension than the original matrix. 
```{r}
# Compute the svd
svd_result <- irlba (M_normalized, nv = 100)

# Plot the singular values
singular_values <- data.frame("Index" = 1:100, "Value" = svd_result$d)
ggplot(singular_values, aes(x = Index, y = Value)) + 
  geom_line() +
  geom_point(color = "blue") + 
  theme_minimal() +
  ggtitle("Top 100 Singular Values of M") +
  xlab("Singular Value Index") 
```


#3.

Assuming 'svd_result' is our SVS result and 'dictionary' is our word list
```{r}
i <- 1
 # Select the i-th singular vector; replace i with the vector number
v_i <- svd_result$v[,i]

# Find indices of the top 10 positive and negative words
top_positive_indices <- order(v_i, decreasing = TRUE)[1:10]
top_negative_indices <- order(v_i)[1:10]

# Map indices back to words
top_positive_words <- dictionary[top_positive_indices]
top_negative_words <- dictionary[top_negative_indices]

# Print words
print(list(positive = top_positive_words, negative = top_negative_words))
```
Not all the vectors are easy to interpret. It can be caused by the high dimensionality. The high dimension space might capture complex and subtile relationships that are not immediately apparent. Or it can be caused by overfitting. Some vectors might capture peculiarities of the specific dataset rather than generalizable language pattern. 


# 4.
(a)
```{r}
V <- svd_result$v
# Normalize rows of V to have unit l2 norm
V_norm <- t(apply(V, 1, function(x) x / sqrt(sum(x^2))))
dim(V_norm)

# Find indices of "woman" and "man" in the dictionary
index_woman <- which(dictionary == "woman")
index_man <- which(dictionary == "man")

# Check if indices are found
if(length(index_woman) == 0) cat("Index for 'woman' not found.\n")
if(length(index_man) == 0) cat("Index for 'man' not found.\n")

# Compute V_diff only if both indices are found
if(length(index_woman) > 0 && length(index_man) > 0) {
  V_diff <- V_norm[index_woman, ] - V_norm[index_man, ]
} else {
  stop("Cannot compute V_diff, one of the indices not found.")
}
```

For each word in your specified list, find its embedding, project it onto V, and store the projection value.
```{r}
# List of words
words_list <- c("boy", "girl", "brother", "sister", "king", "queen", "he", "she", "john", "mary", "wall", "tree" )

#Initialize a vector to store projection values
projections <- numeric(length(words_list))

#Compute projections
for (i in 1: length(words_list)) {
  index_word <- which(dictionary == words_list[i])
  projections[i] <- sum(V_norm[index_word, ] * V_diff)
}
```

Plot the Projection
```{r}
# Create a data frame for plotting
projections_df <- data.frame(word = words_list, projection = projections)

# Plot
ggplot(projections_df, aes(x = projection, y = jitter(rep(1, length(projection))), label = word)) +
  geom_text(size = 3, position = position_jitter(width = 0.1, height = 0), vjust = 0) +
  geom_vline(xintercept = 0, linetype="dashed") +
  xlim(range(projections_df$projection) * c(1.1, 1.1)) + # Adjust x limits slightly
  theme_minimal() +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  xlab("Projection onto 'woman' - 'man' vector") +
  ggtitle("Word Embeddings Projected onto 'woman' - 'man'")

```
It is obvious to observe that words that have strong gender associations, such as "king" and "queen" or "he" and "she" cluster at opposite side of the projection line. This demonstrates that the embeddings ability to capture gender-related semantic differences. Words with little or no inherent gender association, like "tree" or "wall", cluster near the center of the projection line, which indicates that a lower projection value that signifies neutrality in the axis. 
Another significant observation is that the potential biases present in the embeddings. The occupations strongly cluster towards left (man) without a clear rationale, it may reflect societal biases encoded in the training data.


(b)
```{r}
words_list <- c("math", "matrix", "history", "nurse", "doctor", "pilot", "teacher", "engineer", "science", "arts", "literature", "bob", "alice")

#Initialize a vector to store projection values
projections <- numeric(length(words_list))

#Compute projections
for (i in 1: length(words_list)) {
  index_word <- which(dictionary == words_list[i])
  projections[i] <- sum(V_norm[index_word, ] * V_diff)
}

# Create a data frame for plotting
projections_df <- data.frame(word = words_list, projection = projections)

# Plot
ggplot(projections_df, aes(x = projection, y = jitter(rep(1, length(projection))), label = word)) +
  geom_text(size = 3, position = position_jitter(width = 0.1, height = 0), vjust = 0) +
  geom_vline(xintercept = 0, linetype="dashed") +
  xlim(range(projections_df$projection) * c(1.1, 1.1)) + 
  theme_minimal() +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  xlab("Projection") +
  ggtitle("Projection of Word Embeddings onto v")

```
Observations:
We observed that profession-related words distribute differently along the axis depending on what v represents. For instance, if v captures a traditional gender role stereotype, professions like "nurse" or "engineer" might skew towards opposite ends. Also, the placement of gender-neutral names like "bob" and "alice" might reveal biases in the embeddings. For example, if "alice" projects closer to traditionally female-associated professions irrespective of the actual semantic axis, it could indicate embedded gender biases.

Potential Problems:
If systems like LinkedIn's job candidate search rely on such embeddings, they might inadvertently perpetuate gender stereotypes or biases. A resume mentioning "nurse" might be algorithmically favored for female candidates or vice versa with "engineer" for male candidates, regardless of the individual's qualifications or the job's gender relevance, which leads to unfair treatment and violates principles of equality. 

(c)
Adaptive Contextual Debiasing (ACD) can be applied, which involves dynamically adjusting word embeddings based on the context in which they're used, leveraging the insight that the relevance of certain biases (e.g., gender, age, race) varies significantly across different applications.
First, identify vectors in the embedding space that represent specific biases (e.g., gender bias) by analyzing differences between word pairs known to embody these biases.Next, develop a mechanism to assess when and to what extent various biases are relevant or harmful in specific application contexts. Then adjust  embedding according to the contextual bias assessment. Lastly,  incorporate feedback loops and continuous monitoring to refine the bias assessment and adjustment processes over time, ensuring they remain aligned with evolving ethical standards and societal norms.



#5.

(a)
```{r}
# Find the index of "montreal" in the dictionary
index_montreal <- which(dictionary == "montreal")

# Get the embedding for "montreal"
embedding_montreal <- V_norm[index_montreal, , drop = FALSE]  # drop=FALSE ensures it stays as a matrix

# Compute the similarity of "montreal" to all words in the vocabulary
similarities <- V_norm %*% t(embedding_montreal)

# Convert similarities to a vector
similarities_vector <- as.numeric(similarities)

# Replace the similarity of "montreal" to itself with -1 so it doesn't get picked as most similar
similarities_vector[index_montreal] <- -1

# Find the indices of the words with the highest similarity to "montreal"
highest_similarity_indices <- order(similarities_vector, decreasing = TRUE)[1:10]

# Get the words with the highest similarity
most_similar_words <- dictionary[highest_similarity_indices]

# Print the most similar words to "montreal"
print(most_similar_words)

```


(b) 
```{r hello}
# Loading analogy tasks from a CSV file
analogy_tasks <- read.csv('/Users/paulmandelos/Downloads/analogy_task.txt', header = FALSE)

correct_answers <- 0

for (i in 1:nrow(analogy_tasks)) {
  row <- analogy_tasks[i, ]
  row <- as.list(strsplit(row, '\\s+')[[1]])
  A <- row[1]
  B <- row[2]
  C <- row[3]
  correct_answer <- row[4]
  idx_A <- which(dictionary == A[[1]][1])
  idx_B <- which(dictionary == B[[1]][1])
  idx_C <- which(dictionary == C[[1]][1])

  if (length(idx_A) == 0 || length(idx_B) == 0 || length(idx_C) == 0) {
    cat("Skipping: ", A[[1]][1], B[[1]][1], C[[1]][1], " - One of the words not found.\n")
    next  # Skip if any word is not found
  }

  target_vector <- V_norm[idx_B, ] - V_norm[idx_A, ] + V_norm[idx_C, ]
  similarities <- as.numeric(V_norm %*% target_vector)
  similarities[idx_A] <- -Inf
  similarities[idx_B] <- -Inf
  similarities[idx_C] <- -Inf

  predicted_idx <- which.max(similarities)
  
  top5words <- sort(similarities, index.return=TRUE, decreasing=TRUE)
  indecies <- lapply(top5words, `[`, top5words$x %in% head(unique(top5words$x),5))
  predicted_word <- dictionary[predicted_idx]
  #cat("Analogy: ", A[[1]][1], ":", B[[1]][1], "::", C[[1]][1], ":", predicted_word, "\n")
  if (!is.na(predicted_word) && predicted_word == correct_answer) {
    correct_answers <- correct_answers + 1
  }
  if (predicted_word != correct_answer) {
    i <- 1
    cat("Analogy: ", A[[1]][1], ":", B[[1]][1], "::", C[[1]][1], ":", correct_answer[[1]], "\n")
    for (x in indecies[[2]]) {
      new_word <- dictionary[x]
      cat("\t","Predicted word with position",i,"is",new_word,"\n")
      i<-i+1
    }
    
    
  }
}

accuracy <- correct_answers / nrow(analogy_tasks)
cat("Accuracy:", accuracy, "\n")
```
We got a total accuracy of 54%. The analogy that does particularly well is the plural word analogy. On the other hand, the analogies that tend to do poorly are words with more complex connections such as King - Queen (male - female). Another observations is that the capitals of States (Denver - Colorado) performed worse than the capitals of countries (Ottowa - Canada), this can be for any number of reasons but I suspect that countries are more often talked about and thus have a bigger, more stable data to pull from. 
Here are the three examples:
(1)
Analogy:  write : writes :: talk : talks 
	 Predicted word with position 1 is news 
	 Predicted word with position 2 is weekday 
	 Predicted word with position 3 is reporter 
	 Predicted word with position 4 is morning 
	 Predicted word with position 5 is commentator 
(2)
Analogy:  lion : lions :: cloud : clouds 
	 Predicted word with position 1 is flames 
	 Predicted word with position 2 is jets 
	 Predicted word with position 3 is panthers 
	 Predicted word with position 4 is giants 
	 Predicted word with position 5 is eagles 
(3)
Analogy:  horse : horses :: eagle : eagles 
	 Predicted word with position 1 is hawk 
	 Predicted word with position 2 is falcon 
	 Predicted word with position 3 is dove 
	 Predicted word with position 4 is lion 
	 Predicted word with position 5 is deer
	 
In example one, the 5 predicted words have to do with broadcasting, something that write, writes and talk all have in common. 
In example two, the 5 given names are the names of North American sports teams, it is very likely that the most often time the word "lions" is being brought up in western media is to talk about the Detroit Lions, an NFL team. 
In example three, the 5 predicted words are all animals, indicating that the connection was made with animals but they are the wrong ones.
(c)
Here we will be applying two things, PCA and embedding refinement. We will also be combining both to see the different results.
```{r part5c}
# Apply PCA
pca_result <- prcomp(V_norm, center = FALSE)
# Examine the variance to decide on the number of components to keep
plot(pca_result$sdev^2 / sum(pca_result$sdev^2), type = 'b', xlab = "Principal Component", ylab = "Variance Explained")
# Transform the embeddings
k <- 90  # For example, keeping the first 50 components
V_PCA <- pca_result$x[, 1:k]

# Refine embeddings by subtracting the mean and then normalizing
mean_vector <- rowMeans(V_norm)
refined_embeddings <- sweep(V_norm, 1, mean_vector, "-")
V_embed <- t(apply(refined_embeddings, 1, function(x) x / sqrt(sum(x^2))))

#Perform Both
mean_vector <- rowMeans(V_PCA)
refined_embeddings <- sweep(V_PCA, 1, mean_vector, "-")
V_both <- t(apply(refined_embeddings, 1, function(x) x / sqrt(sum(x^2))))
```

```{r runningTask}
correct_answers <- 0
lst<-list(V_norm,V_PCA,V_embed,V_both)
for (V in lst) {
for (i in 1:nrow(analogy_tasks)) {
  row <- analogy_tasks[i, ]
  row <- as.list(strsplit(row, '\\s+')[[1]])
  A <- row[1]
  B <- row[2]
  C <- row[3]
  correct_answer <- row[4]
  idx_A <- which(dictionary == A[[1]][1])
  idx_B <- which(dictionary == B[[1]][1])
  idx_C <- which(dictionary == C[[1]][1])

  if (length(idx_A) == 0 || length(idx_B) == 0 || length(idx_C) == 0) {
    cat("Skipping: ", A[[1]][1], B[[1]][1], C[[1]][1], " - One of the words not found.\n")
    next  # Skip if any word is not found
  }
  #No changes
  target_vector <- V[idx_B, ] - V[idx_A, ] + V[idx_C, ]
  similarities <- as.numeric(V %*% target_vector)
  similarities[idx_A] <- -Inf
  similarities[idx_B] <- -Inf
  similarities[idx_C] <- -Inf

  predicted_idx <- which.max(similarities)
  top5words <- 
  predicted_word <- dictionary[predicted_idx]
  #cat("Analogy: ", A[[1]][1], ":", B[[1]][1], "::", C[[1]][1], ":", predicted_word, "\n")
  if (!is.na(predicted_word) && predicted_word == correct_answer) {
    correct_answers <- correct_answers + 1
  }
  if (predicted_word)
}

accuracy <- correct_answers / nrow(analogy_tasks)
cat("Accuracy:", accuracy, "\n")
correct_answers <- 0
}
```
We see that PCA performed extremely poorly with an Accuracy of 13%. This is with 50 principal components. The accuracy for the refined embedding (normalizing) is roughly similar to the no changes accuracy. This implies that normalizing the vectors does not accomplish anything. We first thought to use PCA to reduce the amount of noise in the data and pick up on the most important trends in the data.For the normalization, we decided it was a low-cost approach to try to improve the accuracy of our task.
